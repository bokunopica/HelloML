{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim # 神经网络+优化函数\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081))\n",
    "])\n",
    "trainset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.c1 = nn.Conv2d(1, 6, (5,5)) # connect_1: 输入1张灰度图，输出6张特征图()，5x5的卷积核过滤器\n",
    "        self.c3 = nn.Conv2d(6, 16, (5,5)) # connect_3: 输入6张特征图，输出16张特征图(8*8)，5x5的卷积核过滤器\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) # full_connect_1: 输入为池化层S4中的所有的特征点(16*4*4)(每张池化后的特征图为4*4)，输出为120个神经元\n",
    "        self.fc2 = nn.Linear(120, 84) # full_connect_2: 120->84\n",
    "        self.fc3 = nn.Linear(84, 10) # full_connect_3: 84->outputs(10个数字分类0~9)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x) # connect_1\n",
    "        x = torch.relu(x) # 激活函数-增加模型非线性拟合能力\n",
    "        x = torch.max_pool2d(x, 2) # 池化层s1 池化窗口为2*2 方式为最大值池化 16*16图片池化为8*8图片\n",
    "\n",
    "        x = self.c3(x) # connect_3\n",
    "        x = torch.relu(x)\n",
    "        x = torch.max_pool2d(x, 2) # 池化层s2 池化窗口为2*2 方式为最大值池化 8*8图片池化为4*4图片\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x)) # x由高维矩阵转化为向量形式\n",
    "        x = self.fc1(x) # full_connect_1\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x) # full_connect_2\n",
    "        x = torch.relu(x) \n",
    "        x = self.fc3(x) # full_connect_3 x->outputs\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet() # 卷积神经网络LeNet\n",
    "if torch.cuda.is_available():\n",
    "    lenet = lenet.cuda()\n",
    "\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=0.001, momentum=0.9) # momentum 梯度下降时的惯性 每次梯度下降优化时加上momentum*上一次梯度优化的值\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# batch_size 一次性加载数据量 shuffle 是否打乱 num_workers 进程数量\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs=1):\n",
    "    cuda = torch.cuda.is_available()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if(i%1000==999):\n",
    "                print(f'[Epoch:{epoch+1}, Batch:{i+1}] Loss: {round(running_loss/1000, 3)}')\n",
    "                running_loss = 0.0\n",
    "    print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1, Batch:1000] Loss: 1.449\n",
      "[Epoch:1, Batch:2000] Loss: 0.317\n",
      "[Epoch:1, Batch:3000] Loss: 0.23\n",
      "[Epoch:1, Batch:4000] Loss: 0.182\n",
      "[Epoch:1, Batch:5000] Loss: 0.142\n",
      "[Epoch:1, Batch:6000] Loss: 0.113\n",
      "[Epoch:1, Batch:7000] Loss: 0.121\n",
      "[Epoch:1, Batch:8000] Loss: 0.105\n",
      "[Epoch:1, Batch:9000] Loss: 0.1\n",
      "[Epoch:1, Batch:10000] Loss: 0.115\n",
      "[Epoch:1, Batch:11000] Loss: 0.097\n",
      "[Epoch:1, Batch:12000] Loss: 0.097\n",
      "[Epoch:1, Batch:13000] Loss: 0.093\n",
      "[Epoch:1, Batch:14000] Loss: 0.078\n",
      "[Epoch:1, Batch:15000] Loss: 0.082\n",
      "[Epoch:2, Batch:1000] Loss: 0.079\n",
      "[Epoch:2, Batch:2000] Loss: 0.075\n",
      "[Epoch:2, Batch:3000] Loss: 0.077\n",
      "[Epoch:2, Batch:4000] Loss: 0.057\n",
      "[Epoch:2, Batch:5000] Loss: 0.075\n",
      "[Epoch:2, Batch:6000] Loss: 0.057\n",
      "[Epoch:2, Batch:7000] Loss: 0.065\n",
      "[Epoch:2, Batch:8000] Loss: 0.07\n",
      "[Epoch:2, Batch:9000] Loss: 0.071\n",
      "[Epoch:2, Batch:10000] Loss: 0.054\n",
      "[Epoch:2, Batch:11000] Loss: 0.065\n",
      "[Epoch:2, Batch:12000] Loss: 0.056\n",
      "[Epoch:2, Batch:13000] Loss: 0.055\n",
      "[Epoch:2, Batch:14000] Loss: 0.072\n",
      "[Epoch:2, Batch:15000] Loss: 0.061\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "train(lenet, criterion, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lenet, 'model/model.pk1') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = torch.load('model/model.pk1') # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lenet.state_dict(), 'model/model_state.pk1') # 保存模型参数\n",
    "# lenet.load_state_dict(torch.load('model/model_state.pk1')) # 保存模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(model, path):\n",
    "    if os.path.exists(path):\n",
    "        model.load_state_dict(torch.load(path))\n",
    "\n",
    "def save_param(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98.69999694824219%\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "def test(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cuda = torch.cuda.is_available()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum()\n",
    "    print(f'Accuracy on the test set: {100*correct/total}%')\n",
    "\n",
    "test(testloader, lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]), tensor([7, 2, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in testloader:\n",
    "    print(data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
