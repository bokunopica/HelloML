{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHILOGjOQbsQ"
      },
      "source": [
        "# **Pytorch Tutorial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C1zA7GupxdJv"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eqj90EkWbWx"
      },
      "source": [
        "**1. Pytorch Documentation Explanation with torch.max**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JCXOg-iSQuk7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.7739, -0.5273, -0.6627, -2.3531,  0.4345],\n",
            "        [-1.1546,  0.4042,  0.5876,  1.6503,  0.2581],\n",
            "        [ 0.3521,  0.4189, -0.1243, -0.7088, -1.2022],\n",
            "        [ 0.7384, -0.7036,  1.6616, -1.5933, -0.8553]])\n",
            "tensor([[-1.3002, -0.1374, -0.9435, -0.0197,  0.6155],\n",
            "        [ 0.9696, -0.2679, -1.5614,  0.2913, -1.0361],\n",
            "        [ 0.6776,  0.8934, -1.1172,  1.3839,  0.1024],\n",
            "        [-1.2619, -1.0527,  1.1889,  0.3001, -0.4432]])\n",
            "tensor([[-0.8736,  0.4311, -0.6064,  0.4901,  0.2984],\n",
            "        [ 0.1861, -0.0986, -1.5059, -0.4095,  1.7664],\n",
            "        [ 0.2681, -0.0733, -0.4028,  0.2962,  0.8948],\n",
            "        [-1.1578,  1.1412, -0.1512,  1.0297, -0.4555]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4,5)\n",
        "y = torch.randn(4,5)\n",
        "z = torch.randn(4,5)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.zeros(2,3, dtype=torch.int64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EEqa9GFoWF78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6616)\n"
          ]
        }
      ],
      "source": [
        "# 1. max of entire tensor (torch.max(input) → Tensor)\n",
        "m = torch.max(x)\n",
        "print(m)\n",
        "# max = x[0][0]\n",
        "# for row in x:\n",
        "#     for col in row:\n",
        "#         if col>max:\n",
        "#             max = col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wffThGDyWKxJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7384, 0.4189, 1.6616, 1.6503, 0.4345])\n",
            "tensor([3, 2, 3, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2. max along a dimension (torch.max(input, dim, keepdim=False, *, out=None) → (Tensor, LongTensor))\n",
        "m, idx = torch.max(x,0)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oKDQW3tIXKg-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7384, 0.4189, 1.6616, 1.6503, 0.4345])\n",
            "tensor([3, 2, 3, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2-2\n",
        "m, idx = torch.max(input=x,dim=0)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6QZ6WRLyX3De"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7384, 0.4189, 1.6616, 1.6503, 0.4345])\n",
            "tensor([3, 2, 3, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2-3\n",
        "m, idx = torch.max(x,0,False)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nqGuctkKbUEn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7384, 0.4189, 1.6616, 1.6503, 0.4345]])\n",
            "tensor([[3, 2, 3, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "# 2-4\n",
        "m, idx = torch.max(x,dim=0,keepdim=True)\n",
        "print(m)\n",
        "print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "9OMzxuMlZPIu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7384, 0.4189, 1.6616, 1.6503, 0.4345])\n",
            "tensor([3, 2, 3, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# 2-5\n",
        "dim_m = torch.Tensor.dim(m)\n",
        "dim_idx = torch.Tensor.dim(idx)\n",
        "if dim_m>=2:\n",
        "    for i in range(dim_m-1):\n",
        "        m = m[0]\n",
        "if dim_idx>=2:\n",
        "    for i in range(dim_idx-1):\n",
        "        idx = idx[0]\n",
        "p = (m, idx)\n",
        "# p = (m[0],idx[0]) # 2-4的例子中m与idx维数进行调整来应对torch.max的输出 m[0] idx[0]\n",
        "torch.max(x,0,False,out=p)\n",
        "print(p[0])\n",
        "print(p[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uhd4TqGTbD2c"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "max() received an invalid combination of arguments - got (Tensor, int, bool, tuple), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !bool!, !tuple of (Tensor, Tensor)!)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 2-6 错误示范，因为顺序原因out=p必须指定参数名\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p \u001b[39m=\u001b[39m (m,idx)\n\u001b[1;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mmax(x,\u001b[39m0\u001b[39;49m,\u001b[39mFalse\u001b[39;49;00m,p)\n",
            "\u001b[1;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, int, bool, tuple), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n      didn't match because some of the arguments have invalid types: (Tensor, !int!, !bool!, !tuple of (Tensor, Tensor)!)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
          ]
        }
      ],
      "source": [
        "# 2-6 错误示范，因为顺序原因out=p必须指定参数名\n",
        "p = (m,idx)\n",
        "torch.max(x,0,False,p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "wbxjUSOXxN0n"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "max() received an invalid combination of arguments - got (Tensor, bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 2-7\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m m, idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(x,\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
          ]
        }
      ],
      "source": [
        "# 2-7\n",
        "m, idx = torch.max(x,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "iMwhGLlGWYaR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.7739, -0.1374, -0.6627, -0.0197,  0.6155],\n",
            "        [ 0.9696,  0.4042,  0.5876,  1.6503,  0.2581],\n",
            "        [ 0.6776,  0.8934, -0.1243,  1.3839,  0.1024],\n",
            "        [ 0.7384, -0.7036,  1.6616,  0.3001, -0.4432]])\n"
          ]
        }
      ],
      "source": [
        "# 3. max(choose max) operators on two tensors (torch.max(input, other, *, out=None) → Tensor)\n",
        "t = torch.max(x,y)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m c \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(a,b)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(c)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# tensors should be the same size in torch.max(tensor1, tensor2)\n",
        "a = torch.randn(3,3)\n",
        "b = torch.randn(2,2)\n",
        "c = torch.max(a,b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFxRKu2Dedwb"
      },
      "source": [
        "**2. Common errors**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMcRyMxGwhul"
      },
      "source": [
        "The following code blocks show some common errors while using the torch library. First, execute the code with error, and then execute the next code block to fix the error. You need to change the runtime to GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX-kKdi6ynFf"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "-muJ4KKreoP2",
        "outputId": "c1d5c3a5-9540-4145-d80c-3cbca18a1deb"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[60], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m])\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m y \u001b[39m=\u001b[39m model(x)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
          ]
        }
      ],
      "source": [
        "# 1. different device error\n",
        "model = torch.nn.Linear(5,1).to(\"cuda:0\")\n",
        "x = torch.Tensor([1,2,3,4,5]).to(\"cpu\")\n",
        "y = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54PqxJLe9-c",
        "outputId": "909d3693-236f-4419-f269-8fb443ef7534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "# 1. different device error (fixed)\n",
        "x = torch.Tensor([1,2,3,4,5]).to(\"cuda:0\")\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "n7OHtZwbi7Qw",
        "outputId": "2a7d2dd0-6498-4da0-9591-3554c1739046"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7fa8b244df3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# 2. mismatched dimensions error\n",
        "x = torch.randn(4,5)\n",
        "y= torch.randn(5,4)\n",
        "z = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVynzvrskFCD",
        "outputId": "926dc01c-be6f-48e1-ad39-a5bcecebc513"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 2. mismatched dimensions error (fixed)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y\u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m z \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m y\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(z\u001b[39m.\u001b[39mshape)\n",
            "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "# 2. mismatched dimensions error (fixed)\n",
        "y= y.transpose(0,1)\n",
        "z = x + y\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Hgzgb9gJANod",
        "outputId": "21b58850-b3f1-4f2a-db5d-cc45e47ccbea"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 7.27 GiB (GPU 0; 8.00 GiB total capacity; 1.41 GiB already allocated; 5.52 GiB free; 1.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[67], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m resnet18 \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mresnet18()\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# Neural Networks for Image Recognition\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m2048\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m244\u001b[39m,\u001b[39m244\u001b[39m) \u001b[39m# Create fake data (512 images)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m out \u001b[39m=\u001b[39m resnet18(data\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39m# Use Data as Input and Feed to Model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(out\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.27 GiB (GPU 0; 8.00 GiB total capacity; 1.41 GiB already allocated; 5.52 GiB free; 1.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# 3. cuda out of memory error\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "resnet18 = models.resnet18().to(\"cuda:0\") # Neural Networks for Image Recognition\n",
        "data = torch.randn(2048,3,244,244) # Create fake data (512 images)\n",
        "out = resnet18(data.to(\"cuda:0\")) # Use Data as Input and Feed to Model\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPksKnB_w343",
        "outputId": "fbee46ad-e63e-4bfc-8971-452895dd7a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ],
      "source": [
        "# 3. cuda out of memory error (fixed)\n",
        "for d in data:\n",
        "  out = resnet18(d.to(\"cuda:0\").unsqueeze(0))\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "vqszlxEE0Bk0",
        "outputId": "a698b34d-00a8-4067-ddc5-180cb4c8eeaa"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "expected scalar type Long but found Float",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[69], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m outs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m)\n\u001b[0;32m      5\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m0\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m lossval \u001b[39m=\u001b[39m L(outs,labels) \u001b[39m# Calculate CrossEntropyLoss between outs and labels\u001b[39;00m\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
            "File \u001b[1;32mc:\\MyCodes\\HelloML\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:3034\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3028\u001b[0m         reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3029\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mcross_entropy_loss(\u001b[39minput\u001b[39m, target, weight, _Reduction\u001b[39m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n\u001b[0;32m   3032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbinary_cross_entropy\u001b[39m(\n\u001b[0;32m   3033\u001b[0m     \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m-> 3034\u001b[0m     target: Tensor,\n\u001b[0;32m   3035\u001b[0m     weight: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3036\u001b[0m     size_average: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3037\u001b[0m     reduce: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3038\u001b[0m     reduction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3039\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m   3040\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Function that measures the Binary Cross Entropy between the target and input\u001b[39;00m\n\u001b[0;32m   3041\u001b[0m \u001b[39m    probabilities.\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3071\u001b[0m \u001b[39m        >>> loss.backward()\u001b[39;00m\n\u001b[0;32m   3072\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3073\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target, weight):\n",
            "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ],
      "source": [
        "# 4. mismatched tensor type\n",
        "import torch.nn as nn\n",
        "L = nn.CrossEntropyLoss()\n",
        "outs = torch.randn(5,5)\n",
        "labels = torch.Tensor([1,2,3,4,0])\n",
        "lossval = L(outs,labels) # Calculate CrossEntropyLoss between outs and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZwgwup_1dgS",
        "outputId": "aaf1de76-7ef2-4ca4-b87d-8482a3117249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6215)\n"
          ]
        }
      ],
      "source": [
        "# 4. mismatched tensor type (fixed)\n",
        "labels = labels.long()\n",
        "lossval = L(outs,labels)\n",
        "print(lossval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSuNdA8F06dK"
      },
      "source": [
        "**3. More on dataset and dataloader**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in84z_xu1rE6"
      },
      "source": [
        "A dataset is a cluster of data in a organized way. A dataloader is a loader which can iterate through the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zfh-c22Qqs"
      },
      "source": [
        "Let a dataset be the English alphabets \"abcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "TaiHofty1qKA"
      },
      "outputs": [],
      "source": [
        "dataset = \"abcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0jwhVa12h3a"
      },
      "source": [
        "A simple dataloader could be implemented with the python code \"for\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bWC5Wwbv2egy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n",
            "i\n",
            "j\n",
            "k\n",
            "l\n",
            "m\n",
            "n\n",
            "o\n",
            "p\n",
            "q\n",
            "r\n",
            "s\n",
            "t\n",
            "u\n",
            "v\n",
            "w\n",
            "x\n",
            "y\n",
            "z\n"
          ]
        }
      ],
      "source": [
        "for datapoint in dataset:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n33VKzkG2y2U"
      },
      "source": [
        "When using the dataloader, we often like to shuffle the data. This is where torch.utils.data.DataLoader comes in handy. If each data is an index (0,1,2...) from the view of torch.utils.data.DataLoader, shuffling can simply be done by shuffling an index array. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MXUUKQ65APf"
      },
      "source": [
        "torch.utils.data.DataLoader will need two imformation to fulfill its role. First, it needs to know the length of the data. Second, once torch.utils.data.DataLoader outputs the index of the shuffling results, the dataset needs to return the corresponding data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV5txsjK5j4j"
      },
      "source": [
        "Therefore, torch.utils.data.Dataset provides the imformation by two functions, `__len__()` and `__getitem__()` to support torch.utils.data.Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "A0IEkemJ5ajD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['q']\n",
            "['z']\n",
            "['x']\n",
            "['a']\n",
            "['j']\n",
            "['r']\n",
            "['b']\n",
            "['g']\n",
            "['t']\n",
            "['c']\n",
            "['l']\n",
            "['d']\n",
            "['n']\n",
            "['o']\n",
            "['u']\n",
            "['w']\n",
            "['m']\n",
            "['s']\n",
            "['i']\n",
            "['h']\n",
            "['e']\n",
            "['p']\n",
            "['f']\n",
            "['v']\n",
            "['y']\n",
            "['k']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils.data \n",
        "class ExampleDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return len(self.data)\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset = dataset1,shuffle = True,batch_size = 1)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTt-ZTid9S2n"
      },
      "source": [
        "A simple data augmentation technique can be done by changing the code in `__len__()` and `__getitem__()`. Suppose we want to double the length of the dataset by adding in the uppercase letters, using only the lowercase dataset, you can change the dataset to the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "7Wn3BA2j-NXl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['e']\n",
            "['F']\n",
            "['D']\n",
            "['b']\n",
            "['I']\n",
            "['R']\n",
            "['K']\n",
            "['d']\n",
            "['T']\n",
            "['P']\n",
            "['N']\n",
            "['i']\n",
            "['t']\n",
            "['Z']\n",
            "['C']\n",
            "['B']\n",
            "['a']\n",
            "['c']\n",
            "['G']\n",
            "['L']\n",
            "['J']\n",
            "['Q']\n",
            "['r']\n",
            "['o']\n",
            "['U']\n",
            "['A']\n",
            "['l']\n",
            "['u']\n",
            "['w']\n",
            "['m']\n",
            "['j']\n",
            "['E']\n",
            "['x']\n",
            "['v']\n",
            "['n']\n",
            "['f']\n",
            "['z']\n",
            "['H']\n",
            "['M']\n",
            "['s']\n",
            "['V']\n",
            "['X']\n",
            "['Y']\n",
            "['h']\n",
            "['O']\n",
            "['W']\n",
            "['S']\n",
            "['p']\n",
            "['g']\n",
            "['q']\n",
            "['y']\n",
            "['k']\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data \n",
        "class ExampleDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    if idx >= len(self.data): # if the index >= 26, return upper case letter\n",
        "      return self.data[idx%26].upper()\n",
        "    else: # if the index < 26, return lower case, return lower case letter\n",
        "      return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return 2 * len(self.data) # The length is now twice as large\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = torch.utils.data.DataLoader(dataset = dataset1,shuffle = True,batch_size = 1)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pytorch Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
