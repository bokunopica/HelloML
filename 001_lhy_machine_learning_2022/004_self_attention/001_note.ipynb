{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self-attention层\n",
    "![](img/selfAttention001.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以b1为例 输入通过self_attention层如何得到b1\n",
    "\n",
    "#### 计算两个输入的相关性$\\alpha$ - Dot-product方法\n",
    "![](img/selfAttention002.png)\n",
    "\n",
    "![](img/selfAttention003.png)\n",
    "\n",
    "1. 通过$q^1以及k^n$外带一层激活函数来求得相应的$\\alpha_{1,i}^{'}$\n",
    "  - $\\alpha_{1,i}^{'} = exp(a_{1,i}/\\sum_i exp(\\alpha_{1,j}))$ \n",
    "2. 通过$\\alpha^{'}$以及$v^i$来计算$b^1$\n",
    "  - $b^1 = \\sum_i \\alpha_{1,i}^{'}*v^i$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整的self-attention步骤\n",
    "![](img/selfAttention004.png)\n",
    "![](img/selfAttention005.png)\n",
    "![](img/selfAttention006.png)\n",
    "![](img/selfAttention007.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multihead 数据间有多种不同的相关关系\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
